
import { GoogleGenAI, Part, Content } from "@google/genai";
import { Message } from '../types';

if (!process.env.API_KEY) {
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const SYSTEM_INSTRUCTION = `Você é o CebolaGPT, um assistente de IA prestativo e versátil com um tom levemente divertido, como uma cebola com muitas camadas de conhecimento. Responda em português do Brasil.`;

const buildHistory = (messages: Message[]): Content[] => {
    return messages.map(msg => {
        const parts: Part[] = [];
        if (msg.text) {
            parts.push({ text: msg.text });
        }
        if (msg.attachment && msg.attachment.type === 'image') {
            const [mimeType, base64Data] = msg.attachment.data.split(';base64,');
            parts.push({
                inlineData: {
                    mimeType: mimeType.replace('data:', ''),
                    data: base64Data
                }
            });
        }
        // Model messages with images generated by the AI are not sent back in history
        // but user attachments are.
        return { role: msg.role, parts };
    }).filter(content => content.parts.length > 0);
};

export const streamChatResponse = async (
  history: Message[],
  onChunk: (text: string) => void,
  onComplete: (fullText: string) => void
) => {
  const chatHistory = buildHistory(history.slice(0, -1));

  const chat = ai.chats.create({
    model: 'gemini-2.5-flash-preview-04-17',
    config: {
      systemInstruction: SYSTEM_INSTRUCTION,
    },
    history: chatHistory,
  });

  const lastMessage = history[history.length-1];
  const lastMessageContent = buildHistory([lastMessage]);
  
  if (lastMessageContent.length === 0) {
    const errorMessage = "Não é possível enviar uma mensagem vazia.";
    console.error(errorMessage);
    onComplete(errorMessage);
    return;
  }

  const lastMessageParts = lastMessageContent[0].parts;

  try {
    const stream = await chat.sendMessageStream({ message: lastMessageParts });
    let fullText = "";
    for await (const chunk of stream) {
      const chunkText = chunk.text;
      if (chunkText) {
        fullText += chunkText;
        onChunk(chunkText);
      }
    }
    onComplete(fullText);
  } catch (error) {
    console.error("Error streaming chat response:", error);
    onComplete("Desculpe, encontrei um erro. Por favor, tente novamente. O erro foi: " + (error as Error).message);
  }
};

export const generateImage = async (prompt: string): Promise<string | null> => {
  try {
    const response = await ai.models.generateImages({
        model: 'imagen-3.0-generate-002',
        prompt: `Um HQ vibrante, estilo de arte de anime de um robô segurando um skate vermelho. ${prompt}`,
        config: {numberOfImages: 1, outputMimeType: 'image/jpeg'},
    });

    if (response.generatedImages && response.generatedImages.length > 0) {
        const base64ImageBytes: string = response.generatedImages[0].image.imageBytes;
        return `data:image/jpeg;base64,${base64ImageBytes}`;
    }
    return null;
  } catch (error) {
    console.error("Error generating image:", error);
    return null;
  }
};
